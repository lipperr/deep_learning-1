{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:09.022845Z","iopub.status.busy":"2024-03-12T12:11:09.022476Z","iopub.status.idle":"2024-03-12T12:11:13.197589Z","shell.execute_reply":"2024-03-12T12:11:13.196751Z","shell.execute_reply.started":"2024-03-12T12:11:09.022804Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, Dataset\n","from sentencepiece import SentencePieceTrainer, SentencePieceProcessor\n","import torch.nn.functional as F\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","from tqdm.autonotebook import tqdm\n","\n","import wandb\n","from pathlib import Path\n","Path('/kaggle/working/model').mkdir(parents=True, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:13.199832Z","iopub.status.busy":"2024-03-12T12:11:13.199479Z","iopub.status.idle":"2024-03-12T12:11:16.439547Z","shell.execute_reply":"2024-03-12T12:11:16.438617Z","shell.execute_reply.started":"2024-03-12T12:11:13.199781Z"},"trusted":true},"outputs":[],"source":["# key = ''\n","# wandb.login(key=key)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.441377Z","iopub.status.busy":"2024-03-12T12:11:16.440843Z","iopub.status.idle":"2024-03-12T12:11:16.446221Z","shell.execute_reply":"2024-03-12T12:11:16.445355Z","shell.execute_reply.started":"2024-03-12T12:11:16.441342Z"},"trusted":true},"outputs":[],"source":["UNK_IDX = 0\n","BOS_IDX = 1\n","EOS_IDX = 2\n","PAD_IDX = 3"]},{"cell_type":"markdown","metadata":{},"source":["### Data (loaders, preprocessing)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.449875Z","iopub.status.busy":"2024-03-12T12:11:16.449507Z","iopub.status.idle":"2024-03-12T12:11:16.473994Z","shell.execute_reply":"2024-03-12T12:11:16.473056Z","shell.execute_reply.started":"2024-03-12T12:11:16.449841Z"},"trusted":true},"outputs":[],"source":["def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","\n","def yield_tokens(tokenizer, texts):\n","    for text_sample in tqdm(texts, desc=\"Building vocab\"):\n","        sentence = tokenizer(text_sample)\n","        for token in sentence:\n","            yield token\n","\n","\n","\n","class TextDataset(Dataset):\n","\n","    def __init__(self, type, path_src, path_tgt='', path_vocab='vocabs', vocab_size=50000):\n","        self.type = type\n","        self.path_src = path_src\n","        self.lang_src = 'de'\n","        self.path_tgt = path_tgt\n","        self.lang_tgt = 'en'\n","\n","        self.vocab_size = vocab_size\n","\n","        self.texts = {'de':[], 'en':[]}\n","        with open(self.path_src, encoding=\"utf-8\") as f:\n","            self.texts[self.lang_src] = [line.rstrip() for line in f.readlines()]\n","        \n","        if self.type != 'test':\n","            with open(self.path_tgt, encoding=\"utf-8\") as f:\n","                self.texts[self.lang_tgt] = [line.rstrip() for line in f.readlines()]\n","\n","        self.token_transform = {}\n","\n","        if not os.path.isfile('tokenizer_src.model'):\n","            SentencePieceTrainer.train(\n","                input=self.path_src, vocab_size=self.vocab_size,\n","                model_type='word', model_prefix='tokenizer_src',\n","                normalization_rule_name='nmt_nfkc_cf',\n","                pad_id = PAD_IDX,\n","                unk_surface='<unk>'\n","            )\n","        self.token_transform[self.lang_src] = SentencePieceProcessor(model_file='tokenizer_src.model')\n","\n","        if self.type != 'test':\n","            if not os.path.isfile('tokenizer_tgt.model'):\n","                SentencePieceTrainer.train(\n","                    input=self.path_tgt, vocab_size=self.vocab_size,\n","                    model_type='word', model_prefix='tokenizer_tgt',\n","                    normalization_rule_name='nmt_nfkc_cf',\n","                    pad_id = PAD_IDX,\n","                    unk_surface='<unk>'\n","                )\n","            self.token_transform[self.lang_tgt] = SentencePieceProcessor(model_file='tokenizer_tgt.model')\n","\n","            \n","        self.text_transform = {}\n","        \n","        self.text_transform[self.lang_src] = sequential_transforms(\n","            self.token_transform[self.lang_src].encode, TextDataset.tensor_transform)\n","        \n","        if self.type != 'test':\n","            self.text_transform[self.lang_tgt] = sequential_transforms(\n","                self.token_transform[self.lang_tgt].encode, TextDataset.tensor_transform)\n","\n","    @staticmethod\n","    def tensor_transform(token_ids):\n","        return torch.cat((torch.tensor([BOS_IDX]),\n","                        torch.tensor(token_ids),\n","                        torch.tensor([EOS_IDX])))\n","    \n","    def __len__(self):\n","        return len(self.texts[self.lang_src])\n","\n","\n","    def __getitem__(self, index):\n","        if self.type != 'test':\n","            return tuple([self.text_transform[self.lang_src](self.texts[self.lang_src][index]), self.text_transform[self.lang_tgt](self.texts[self.lang_tgt][index])])\n","        return tuple([self.text_transform[self.lang_src](self.texts[self.lang_src][index])])\n","        \n","    def collate(self, batch):\n","        maxlen = 0\n","        \n","        if self.type != 'test':\n","            maxlen = max([max(batch[i][0].shape[0], batch[i][1].shape[0]) for i in range(len(batch))])\n","        else:\n","            maxlen = max([batch[i][0].shape[0] for i in range(len(batch))])\n","\n","        src_batch = torch.Tensor([torch.cat((b[0], torch.full((maxlen - b[0].shape[0], ), fill_value=3))).numpy() for b in batch])\n","\n","\n","        if self.type == 'test':\n","            return src_batch.T\n","\n","        tgt_batch = torch.Tensor([torch.cat((b[1], torch.full((maxlen - b[1].shape[0], ), fill_value=3))).numpy() for b in batch])\n","\n","\n","        return src_batch.T, tgt_batch.T\n"]},{"cell_type":"markdown","metadata":{},"source":["### Model architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.475679Z","iopub.status.busy":"2024-03-12T12:11:16.475351Z","iopub.status.idle":"2024-03-12T12:11:16.495935Z","shell.execute_reply":"2024-03-12T12:11:16.495092Z","shell.execute_reply.started":"2024-03-12T12:11:16.475649Z"},"trusted":true},"outputs":[],"source":["class PositionalEncoding(nn.Module):\n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* np.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding', pos_embedding)\n","\n","    def forward(self, token_embedding):\n","        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens):\n","        return self.embedding(tokens.long()) * np.sqrt(self.emb_size)\n","\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        self.transformer = nn.Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src,\n","                trg,\n","                src_mask,\n","                tgt_mask,\n","                src_padding_mask,\n","                tgt_padding_mask,\n","                memory_key_padding_mask):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src, src_mask):\n","        return self.transformer.encoder(self.positional_encoding(\n","                            self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt, memory, tgt_mask):\n","        return self.transformer.decoder(self.positional_encoding(\n","                          self.tgt_tok_emb(tgt)), memory,\n","                          tgt_mask)\n","\n","def attention_mask(size, device):\n","    mask = (torch.triu(torch.ones((size, size), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","def create_mask(src, tgt, device):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = attention_mask(tgt_seq_len, device)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len),device=device).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"]},{"cell_type":"markdown","metadata":{},"source":["### Train and validate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.497595Z","iopub.status.busy":"2024-03-12T12:11:16.497207Z","iopub.status.idle":"2024-03-12T12:11:16.520155Z","shell.execute_reply":"2024-03-12T12:11:16.519162Z","shell.execute_reply.started":"2024-03-12T12:11:16.497563Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    def __init__(self, model, device, optimizer, criterion, model_saver):\n","        self.model = model\n","        self.model = self.model.to(device)\n","        self.device = device\n","\n","        self.optimizer = optimizer\n","        self.criterion = criterion\n","        \n","        self.model_saver = model_saver\n","\n","\n","    def train_epoch(self, dataloader, desc):\n","        self.model.train()\n","        losses = 0\n","        \n","        for src, tgt in tqdm(dataloader, desc):\n","\n","            src = src.type(torch.long)\n","            tgt = tgt.type(torch.long)\n","\n","            src = src.to(self.device)\n","            tgt = tgt.to(self.device)\n","\n","            tgt_input = tgt[:-1, :]\n","\n","            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, self.device)\n","\n","            logits = self.model(src, tgt_input, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","            self.optimizer.zero_grad()\n","\n","            tgt_out = tgt[1:, :]\n","            loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","            loss.backward()\n","\n","            self.optimizer.step()\n","            losses += loss.item()\n","            \n","        return losses / len(list(dataloader))\n","\n","\n","    def evaluate(self, dataloader, desc):\n","        self.model.eval()\n","        losses = 0\n","\n","        for src, tgt in tqdm(dataloader, desc):\n","            src = src.type(torch.long)\n","            tgt = tgt.type(torch.long)\n","            \n","            src = src.to(self.device)\n","            tgt = tgt.to(self.device)\n","\n","            tgt_input = tgt[:-1, :]\n","\n","            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input, self.device)\n","\n","            logits = self.model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n","\n","            tgt_out = tgt[1:, :]\n","            loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n","            losses += loss.item()\n","\n","        return losses / len(list(dataloader))\n","\n","\n","\n","    def train(self, train_loader, val_loader, n_epochs, start_epoch=0, continue_training=False, model_path='model/saved_model.pth', log=True):\n","        if continue_training:\n","            start_epoch = self.load_model(model_path)\n","        for epoch in range(start_epoch, n_epochs):\n","            \n","            torch.cuda.empty_cache()\n","            gc.collect()\n","            \n","            train_loss = self.train_epoch(train_loader, f'Training epoch {epoch}/{n_epochs}')\n","            val_loss = self.evaluate(val_loader, f'Validating epoch {epoch}/{n_epochs}')\n","            \n","            print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")\n","            self.model_saver(val_loss, epoch, self.model, self.optimizer, model_path)\n","            if log:\n","                wandb.log({'train_loss':train_loss, 'val_loss':val_loss})\n","\n","            \n","            \n","            \n","    def load_model(self, model_path='model/saved_model.pth'):\n","        checkpoint = torch.load(model_path)\n","        self.model.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        return checkpoint['epoch']\n","        \n","        \n","        \n","        \n","class SaveModel:\n","    def __init__(self, save_best=False, best_val_loss=torch.inf):\n","        self.save_best = save_best\n","        self.best_val_loss = best_val_loss\n","        \n","    def __call__(self, val_loss, epoch, model, optimizer, model_path='/kaggle/working/saved_model.pth'):\n","        \n","        if val_loss < self.best_val_loss or not self.save_best:\n","            self.best_val_loss = val_loss\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict()}, model_path)\n","            print('New best model with loss {:.5f} is saved'.format(val_loss))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Translate"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.584900Z","iopub.status.busy":"2024-03-12T12:11:16.584523Z","iopub.status.idle":"2024-03-12T12:11:16.596912Z","shell.execute_reply":"2024-03-12T12:11:16.596063Z","shell.execute_reply.started":"2024-03-12T12:11:16.584846Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def greedy_decode(model, src, src_mask, max_len, start_symbol, device):\n","    src = src.to(device)\n","    src_mask = src_mask.to(device)\n","\n","    memory = model.encode(src, src_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(device)\n","    \n","    for i in range(max_len-1):\n","        memory = memory.to(device)\n","        tgt_mask = (attention_mask(ys.size(0), device)\n","                    .type(torch.bool)).to(device)\n","        out = model.decode(ys, memory, tgt_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat([ys,\n","                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","@torch.no_grad()\n","def translate_1(model, src, device, vocab_transform_tgt):\n","    model.eval()\n","    num_tokens = src.shape[0]\n","    print(num_tokens)\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, device=device).flatten()\n","\n","    ready_tgt_tokens = list(map(int, tgt_tokens.cpu().numpy()))\n","    print(ready_tgt_tokens)\n","    return \"\".join(vocab_transform_tgt(ready_tgt_tokens)).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Run"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.598306Z","iopub.status.busy":"2024-03-12T12:11:16.598012Z","iopub.status.idle":"2024-03-12T12:11:16.608842Z","shell.execute_reply":"2024-03-12T12:11:16.607998Z","shell.execute_reply.started":"2024-03-12T12:11:16.598283Z"},"trusted":true},"outputs":[],"source":["data_dir = '/kaggle/input/bhw-2-translation-dataset/bhw2-data/data/'\n","\n","train_pth = 'train.de-en.'\n","val_pth = 'val.de-en.'\n","test_pth = 'test1.de-en.'\n","\n","src_lang = 'de'\n","tgt_lang = 'en'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.610241Z","iopub.status.busy":"2024-03-12T12:11:16.609963Z","iopub.status.idle":"2024-03-12T12:11:16.617596Z","shell.execute_reply":"2024-03-12T12:11:16.616778Z","shell.execute_reply.started":"2024-03-12T12:11:16.610215Z"},"trusted":true},"outputs":[],"source":["num_encoder_layers = 3\n","num_decoder_layers = 3\n","emb_size = 512\n","nhead = 8\n","dim_feedforward = 1024\n","\n","batch_size = 128\n","vocab_size = 40000\n","n_epochs = 15"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:11:16.619420Z","iopub.status.busy":"2024-03-12T12:11:16.618845Z","iopub.status.idle":"2024-03-12T12:11:16.763703Z","shell.execute_reply":"2024-03-12T12:11:16.762828Z","shell.execute_reply.started":"2024-03-12T12:11:16.619389Z"},"trusted":true},"outputs":[],"source":["SEED = 11\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = False\n","torch.backends.cudnn.benchmark = True\n","np.random.seed(SEED)\n","torch.cuda.empty_cache()\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:14:11.628965Z","iopub.status.busy":"2024-03-12T12:14:11.628025Z","iopub.status.idle":"2024-03-12T12:14:13.516524Z","shell.execute_reply":"2024-03-12T12:14:13.515503Z","shell.execute_reply.started":"2024-03-12T12:14:11.628920Z"},"trusted":true},"outputs":[],"source":["\n","\n","train_dataset = TextDataset('train', data_dir+train_pth+src_lang, data_dir+train_pth+tgt_lang, vocab_size=vocab_size)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=train_dataset.collate)\n","\n","val_dataset = TextDataset('val', data_dir+val_pth+src_lang, data_dir+val_pth+src_lang, vocab_size=vocab_size)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=val_dataset.collate)\n","\n","\n","device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","\n","transformer = Seq2SeqTransformer(num_encoder_layers, num_decoder_layers, emb_size, nhead, vocab_size, vocab_size, dim_feedforward)\n","\n","\n","\n","for p in transformer.parameters():\n","    if p.dim() > 1:\n","        nn.init.xavier_uniform_(p)\n","\n","transformer = transformer.to(device)\n","\n","optimizer = torch.optim.Adam(transformer.parameters(), lr=1e-4, betas=(0.9, 0.98), eps=1e-9)\n","criterion = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX, label_smoothing=0.1)\n","\n","model_saver = SaveModel()\n","trainer = Trainer(transformer, device, optimizer, criterion, model_saver)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-12T12:14:20.637591Z","iopub.status.busy":"2024-03-12T12:14:20.637248Z","iopub.status.idle":"2024-03-12T12:14:52.260772Z","shell.execute_reply":"2024-03-12T12:14:52.259866Z","shell.execute_reply.started":"2024-03-12T12:14:20.637564Z"},"trusted":true},"outputs":[],"source":["run = wandb.init(project='bhw-2')\n","run.watch(transformer)\n","\n","trainer.train(train_loader, val_loader, n_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["### Test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-12T12:11:33.726629Z","iopub.status.idle":"2024-03-12T12:11:33.726985Z","shell.execute_reply":"2024-03-12T12:11:33.726836Z","shell.execute_reply.started":"2024-03-12T12:11:33.726818Z"},"trusted":true},"outputs":[],"source":["test_dataset = TextDataset('test', data_dir+test_pth+src_lang, vocab_size=vocab_size)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn=test_dataset.collate)\n","\n","translated = []\n","\n","for src in tqdm(test_loader):\n","    sentence = translate_1(trainer.model, src, device, train_dataset.token_transform[tgt_lang].decode)\n","    translated.append(sentence)\n","    \n","with open('/kaggle/working/output_1.txt', \"w\") as f:\n","    for sentence in translated:\n","        f.write(sentence + \"\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-04T16:52:59.599855Z","iopub.status.busy":"2024-03-04T16:52:59.599195Z","iopub.status.idle":"2024-03-04T16:52:59.832538Z","shell.execute_reply":"2024-03-04T16:52:59.831407Z","shell.execute_reply.started":"2024-03-04T16:52:59.599821Z"},"trusted":true},"outputs":[],"source":["gc.collect()\n","wandb.finish()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4499174,"sourceId":7706258,"sourceType":"datasetVersion"},{"datasetId":4538522,"sourceId":7760435,"sourceType":"datasetVersion"},{"datasetId":4573824,"sourceId":7809379,"sourceType":"datasetVersion"},{"datasetId":4573931,"sourceId":7809515,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
